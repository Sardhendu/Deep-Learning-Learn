{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports the packages Here\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Cross Validation: (9810, 28, 28) (9810,)\n",
      "Testing: (7709, 28, 28) (7709,)\n"
     ]
    }
   ],
   "source": [
    "# Here we make a call to the dataset and retrieve the training, valid and test data.\n",
    "cleaned_dataset_path = '/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/MNIST_ImageClassification/DataPreparation/dataset_cleaned.p'\n",
    "\n",
    "with open(cleaned_dataset_path, 'rb') as f:\n",
    "    fnl_dataset = pickle.load(f)\n",
    "    training_dataset = (fnl_dataset['training_dataset'])\n",
    "    training_labels = (fnl_dataset['training_labels'])\n",
    "    test_dataset = (fnl_dataset['test_dataset'])\n",
    "    test_labels = (fnl_dataset['test_labels'])\n",
    "    crossvalid_dataset = (fnl_dataset['crossvalid_dataset'])\n",
    "    crossvalid_labels = (fnl_dataset['crossvalid_labels'])\n",
    "    \n",
    "print('Training:', training_dataset.shape, training_labels.shape)\n",
    "print('Cross Validation:', crossvalid_dataset.shape, crossvalid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. For a convolution Neural Network we need a Tensor of shape (batchSize, imageSize, imageSize, numChannels). For a gray scale image the numChannels would be 1 for a RBG it would be 3. The below code will convert the input array into the tensor of said shape. The numChannels would even work without having it. But we have it because it will help us do the matrix multiplication with the specified depth (kernel) for the convolutional filter. Plus Tensor flow requires it this way.\n",
    "\n",
    "\n",
    "2. For labels Tensor flow takes the labels as binary input where 1 indicated the activation of the class of the training instance and 0 for all other class. For example Alphabet A whose binary value is 0 will turn to an array with elements [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0] and B becomes [0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Cross Validation set (9810, 28, 28, 1) (9810, 10)\n",
      "Test set (7709, 28, 28, 1) (7709, 10)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data, the input is in the form of tensor of shape [200000x28x28], Here we convert them into a single row\n",
    "imageSize = 28\n",
    "numChannels = 1 # For Grayscale image.\n",
    "no_of_labels = 10\n",
    "\n",
    "def reshape_data(dataset, labels, sample_size=None):\n",
    "    if sample_size:\n",
    "        dataset = dataset[:sample_size].reshape((-1,imageSize,imageSize,numChannels)) # To reshape the\n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        labels = (np.arange(no_of_labels) == labels[:,None]).astype(np.float32)\n",
    "    else:\n",
    "        dataset = dataset.reshape((-1,imageSize,imageSize,numChannels)) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        labels = (np.arange(no_of_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "# We just reshape the image so that 1 image defines a row\n",
    "\n",
    "# training_dataset[:].reshapeshape\n",
    "trainData_, trainLabels_ = reshape_data(training_dataset, training_labels)\n",
    "validData_, validLabels_ = reshape_data(crossvalid_dataset, crossvalid_labels)\n",
    "testData_, testLabels_ = reshape_data(test_dataset, test_labels)\n",
    "print('Training set', trainData_.shape, trainLabels_.shape)\n",
    "print('Cross Validation set', validData_.shape, validLabels_.shape)\n",
    "print('Test set', testData_.shape, testLabels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-27d8319428ba>, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-27d8319428ba>\"\u001b[0;36m, line \u001b[0;32m104\u001b[0m\n\u001b[0;31m    biasesFC['fcLayer_bias'] = tf.Variable(tf.constant(1.0, shape=[self.h1]))\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Build the Convolution graph using Tensor Flow.\n",
    "\n",
    "# Define Hyperparameter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConvNets():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numClasses = 10\n",
    "        self.ch = 1               # numChannels -> For grayscale =1, for RGB =3\n",
    "        self.h1 = 64              # numHiddenUnits for the fully connected layer\n",
    "        \n",
    "        self.ck1 = 5              # Size of kernel for the first convolution layer\n",
    "        self.ck2 = 5              # Size of kernel for the second convolution layer\n",
    "        self.cd1 = 16             # Number of kernels for the first convolution layer\n",
    "        self.cd2 = 32             # Number of kernels for the second convolution layer\n",
    "        self.cs1 = 1              # Strides for the first convolution layer  \n",
    "        self.cs2 = 1              # Strides for the first convolution layer\n",
    "        \n",
    "        self.pk1 = 2              # Size of kernel for the first Pooling layer\n",
    "        self.pk2 = 2              # Size of kernel for the second Pooling layer  \n",
    "        self.ps1 = 2              # Strides for the first Pooling layer  \n",
    "        self.ps2 = 2              # Strides for the first Pooling layer\n",
    "        \n",
    "        self.alpha = 0.05         # The learning rate\n",
    "        \n",
    "        \n",
    "    def getWeightBiasCVP(self):\n",
    "        weights = {\n",
    "            'convLayer1_wgths' : tf.Variable(tf.truncated_normal([self.ck1,self.ck1,self.ch,self.cd1],stddev=0.1)), \n",
    "            # [kernelSize, kernelSize, numChannels, numKernels]\n",
    "            'convLayer2_wghts' : tf.Variable(tf.truncated_normal([self.ck2,self.ck2,self.cd1,self.cd2],stddev=0.1)) \n",
    "            # [kernelSize, kernelSize, numChannels, numKernels]\n",
    "        }         \n",
    "\n",
    "        biases = {\n",
    "            'convLayer1_bias' : tf.Variable(tf.zeros([self.cd1])),\n",
    "            # [kernelSize]\n",
    "            'convLayer2_bias' : tf.Variable(tf.constant(1.0, shape=[self.cd2]))\n",
    "            # [kernelSize]\n",
    "        }\n",
    "\n",
    "        return weights, biases\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightBiasFC(self,flattenedPoolSize):\n",
    "        # Here we need weigths for the fully connected network\n",
    "        weightsFC ={}\n",
    "        biasesFC = {}\n",
    "        weightsFC['fcLayer_wgths'] = tf.Variable(tf.truncated_normal([flattenedPoolSize, self.h1]))\n",
    "        # 16 is the depth or numkernels\n",
    "        biasesFC['fcLayer_bias'] = tf.Variable(tf.constant(1.0, shape=[self.h1]))\n",
    "        weightsFC['outputLayer_wghts'] = tf.Variable(tf.truncated_normal([self.h1, self.numClasses]))\n",
    "        biasesFC['outputLayer_bias'] = tf.Variable(tf.constant(1.0, shape=[self.numClasses]))\n",
    "        \n",
    "        return weightsFC, biasesFC\n",
    "\n",
    "\n",
    "    \n",
    "    def convLayer(self, data, wgth, bias, stride=1, nlModel='RELU'):\n",
    "        data = tf.nn.conv2d(data, wgth, [1,stride,stride,1], padding='SAME')\n",
    "        # Add Bias\n",
    "        if nlModel == 'RELU':\n",
    "            return tf.nn.relu(data + bias)\n",
    "        elif nlModel == 'LOGIT':\n",
    "            hidden = tf.matmul(data, wgth) + bias\n",
    "            return tf.sigmoid(hidden, name=None)\n",
    "\n",
    "\n",
    "    def poolLayer(self, data, kernel, strides, poolType='MAX'):\n",
    "        if poolType=='MAX':\n",
    "            return tf.nn.max_pool(data, ksize=[1,kernel,kernel,1], strides=[1,strides,strides,1], padding='SAME')\n",
    "        elif poolType == 'AVG':\n",
    "            return tf.nn.avg_pool(data, ksize=[1,kernel,kernel,1], strides=[1,strides,strides,1], padding='SAME')\n",
    "\n",
    "        \n",
    "    def fcLayer(self, data, wght, bias, nModel):\n",
    "        # convert the poolState2 into a flattened neuron structure\n",
    "        data = tf.matmul(data, wght) + bias\n",
    "        if nModel=='RELU':\n",
    "            return tf.nn.relu(data)\n",
    "        if nModel=='LOGIT':\n",
    "            return tf.sigmoid(data, name=None)\n",
    "        \n",
    "    def outputLayer(self, data, wght, bias):\n",
    "        data = tf.matmul(data, wght) + bias\n",
    "        return data, tf.nn.softmax(data, name=None)\n",
    "            \n",
    "        \n",
    "\n",
    "    def convNet(self, batchSize, imageSize, numChannels, numLabels):\n",
    "        \n",
    "        # Input Layer\n",
    "        trainData = tf.placeholder(tf.float32, shape=(batchSize, imageSize, imageSize, self.ch))\n",
    "        trainLabels = tf.placeholder(tf.float32, shape=(batchSize, numLabels))\n",
    "\n",
    "        # Get weights and Biases for the input to Comvolution -> Pooling Layer\n",
    "#         weights, biases = self.getWeightBiasCVP()\n",
    "weightsFC[\n",
    "        # 16 is the depth or numkernels\n",
    "        biasesFC['fcLayer_bias'] = tf.Variable(tf.constant(1.0, shape=[self.h1]))\n",
    "        weightsFC['outputLayer_wghts'] = tf.Variable(tf.truncated_normal([self.h1, self.numClasses]))\n",
    "        biasesFC['outputLayer_bias'] = tf.Variable(tf.constant(1.0, shape=[self.numClasses]))\n",
    "        \n",
    "        weights = {\n",
    "            'convLayer1_wgths' : tf.Variable(tf.truncated_normal([self.ck1,self.ck1,self.ch,self.cd1],stddev=0.1)), \n",
    "            'convLayer2_wghts' : tf.Variable(tf.truncated_normal([self.ck2,self.ck2,self.cd1,self.cd2],stddev=0.1)),\n",
    "            'fcLayer_wgths' : tf.Variable(tf.truncated_normal([7*7*, self.h1]))\n",
    "        }         \n",
    "\n",
    "        biases = {\n",
    "            'convLayer1_bias' : tf.Variable(tf.zeros([self.cd1])),\n",
    "            'convLayer2_bias' : tf.Variable(tf.constant(1.0, shape=[self.cd2]))\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "        # Convolution Layer1 and # Pooling Layer1\n",
    "        convState1 = self.convLayer(trainData, weights['convLayer1_wgths'], biases['convLayer1_bias'], stride=self.cs1, nlModel='RELU')\n",
    "        poolState1 = self.poolLayer(convState1, kernel=self.pk1, strides=self.ps1, poolType='MAX')\n",
    "\n",
    "        # Convolution Layer2 and Pooling Layer 2\n",
    "        convState2 = self.convLayer(poolState1, weights['convLayer2_wghts'], biases['convLayer2_bias'], stride=self.cs2, nlModel='RELU')\n",
    "        poolState2 = self.poolLayer(convState2, kernel=self.pk2, strides=self.ps2, poolType='MAX')\n",
    "        poolSize = poolState2.get_shape().as_list()[1]\n",
    "        \n",
    "        shapew = tf.shape(poolState2)\n",
    "        \n",
    "        # Get weigths and Biases for the Pooling Layer the Fully Connected Hidden Layer\n",
    "        flattenedPoolSize = poolSize*poolSize*self.cd2 \n",
    "        weightsFC, biasesFC = self.getWeightBiasFC(flattenedPoolSize)\n",
    "        \n",
    "        # Fully Connected Hidden Layer, We need to reshape the pool layer into a flattened neuron layer\n",
    "        fcLayerdata = tf.reshape(poolState2, [-1, flattenedPoolSize])   # -1 states no change to the shape at that dimension\n",
    "        fcState = self.fcLayer(fcLayerdata, weightsFC['fcLayer_wgths'], biasesFC['fcLayer_bias'], nModel='RELU')\n",
    "        fc_to_output, outputState = self.outputLayer(fcState, weightsFC['outputLayer_wghts'], biasesFC['outputLayer_bias'])\n",
    "        \n",
    "        # Calculate the Loss\n",
    "        loss_CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(fc_to_output, trainLabels))\n",
    "        \n",
    "        # Optimize The loss Function\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.alpha).minimize(loss_CE)\n",
    "        \n",
    "        # Training Prediction\n",
    "        pred = tf.equal(tf.argmax(outputState, 1), tf.argmax(trainLabels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "        \n",
    "        \n",
    "        return dict(\n",
    "            trainData=trainData,\n",
    "            trainLabels=trainLabels,\n",
    "            convState1=convState1,\n",
    "            poolState1=poolState1,\n",
    "            convState2=convState2,\n",
    "            poolState2=poolState2,\n",
    "            shapew = shapew,\n",
    "            weightsFC=weightsFC['fcLayer_wgths'],\n",
    "            fcLayerdata=fcLayerdata,\n",
    "            fcState=fcState,\n",
    "            fc_to_output=fc_to_output,\n",
    "            loss_CE=loss_CE,\n",
    "            optimizer=optimizer,\n",
    "            pred=pred,\n",
    "            accuracy=accuracy\n",
    "        )\n",
    "        # Fully Connected Layer\n",
    "        # The poolState will result in a Tensor of shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def convLayer(x, w, b, s=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, w, strides=[1, s, s, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxPoolLayer(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def convNet(trainData, trainLabels, weights, biases, batchSize, imageSize, numLabels):\n",
    "    trainData = tf.reshape(trainData, shape=[batchSize, imageSize, imageSize, numChannel])\n",
    "    \n",
    "    # Convolution Layer1 and # Pooling Layer1\n",
    "    convState1 = convLayer(trainData, weights['conv1_wgths'], biases['conv1_bias'])\n",
    "    convState1 = maxPoolLayer(convState1, k=2)\n",
    "\n",
    "    # Convolution Layer2 and Pooling Layer 2\n",
    "    convState2 = convLayer(convState1, weights['conv2_wghts'], biases['conv2_bias'])\n",
    "    convState2 = maxPoolLayer(convState2, k=2)\n",
    "\n",
    "    # Fully Connected Hidden Layer, We need to reshape the pool layer into a flattened neuron layer\n",
    "    fcLayerData = tf.reshape(convState2, [-1, weights['fc_wgths'].get_shape().as_list()[0]])\n",
    "    fcState = tf.add(tf.matmul(fcLayerData, weights['fc_wgths']), biases['fc_bias'])\n",
    "    fcState = tf.nn.relu(fcState)\n",
    "    \n",
    "    # Prediction\n",
    "    outputState = tf.add(tf.matmul(fcState, weights['output_wghts']), biases['output_bias'])\n",
    "\n",
    "    return outputState\n",
    "\n",
    "\n",
    "# Reset The Graph\n",
    "reset_graph()\n",
    "\n",
    "\n",
    "# Define Hyperparameters\n",
    "          # The learning rate\n",
    "\n",
    "\n",
    "# Define the input\n",
    "trainData = tf.placeholder(tf.float32, [None, 784])\n",
    "trainLabels = tf.placeholder(tf.float32, shape=(batchSize, numLabels))\n",
    "    \n",
    "# Define Weigths\n",
    "weights = {\n",
    "    'conv1_wgths' : tf.Variable(tf.truncated_normal([conv1Kernel,conv1Kernel,numChannel,conv1Depth])), \n",
    "    'conv2_wghts' : tf.Variable(tf.truncated_normal([conv2Kernel,conv2Kernel,conv1Depth,conv2Depth])),\n",
    "    'fc_wgths' : tf.Variable(tf.truncated_normal([7*7*conv2Depth, numHidden])),\n",
    "    'output_wghts' : tf.Variable(tf.truncated_normal([numHidden, numLabels]))\n",
    "}         \n",
    "\n",
    "biases = {\n",
    "    'conv1_bias' : tf.Variable(tf.random_normal([conv1Depth])),\n",
    "    'conv2_bias' : tf.Variable(tf.random_normal([conv2Depth])),\n",
    "    'fc_bias' : tf.Variable(tf.random_normal([numHidden])),\n",
    "    'output_bias': tf.Variable(tf.random_normal([numLabels]))\n",
    "}\n",
    "\n",
    "# Get The model estimate\n",
    "estimate = convNet(trainData, trainLabels, weights, biases, batchSize=batchSize, imageSize=28, numLabels=10)\n",
    "\n",
    "# Calculate the Loss and Optimize\n",
    "loss_CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=estimate, labels=trainLabels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=alpha).minimize(loss_CE)\n",
    "\n",
    "# Training Prediction\n",
    "pred = tf.equal(tf.argmax(estimate, 1), tf.argmax(trainLabels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "#     return dict(\n",
    "#         trainData=trainData,\n",
    "#         trainLabels=trainLabels,\n",
    "#         convState1=convState1,\n",
    "#         convState2=convState2,\n",
    "#         fcLayerData=fcLayerData,\n",
    "#         fcState=fcState,\n",
    "#         loss_CE=loss_CE,\n",
    "#         optimizer=optimizer,\n",
    "#         pred=pred,\n",
    "#         accuracy=accuracy\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1280, Minibatch Loss= 40.432938, Training Accuracy= 0.13281\n",
      "Iter 2560, Minibatch Loss= 18.971008, Training Accuracy= 0.07031\n",
      "Iter 3840, Minibatch Loss= 9.288128, Training Accuracy= 0.09375\n",
      "Iter 5120, Minibatch Loss= 5.570509, Training Accuracy= 0.09375\n"
     ]
    }
   ],
   "source": [
    "training_iters = 200000\n",
    "display_step = 10\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batchSize < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batchSize)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={trainData: batch_x, trainLabels: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_CE, accuracy], feed_dict={trainData: batch_x,\n",
    "                                                              trainLabels: batch_y})\n",
    "            print (\"Iter \" + str(step*batchSize) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "#     print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "#                                       y: mnist.test.labels[:256],\n",
    "#                                       keep_prob: 1.})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 21.263004, Training Accuracy= 0.07812\n",
      "Iter 2560, Minibatch Loss= 11.673630, Training Accuracy= 0.09375\n",
      "Iter 3840, Minibatch Loss= 5.153423, Training Accuracy= 0.10156\n",
      "Iter 5120, Minibatch Loss= 3.666912, Training Accuracy= 0.06250\n",
      "Iter 6400, Minibatch Loss= 3.051682, Training Accuracy= 0.12500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bd8b314fec3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# print (graphDict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-bd8b314fec3e>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mbatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainLabels_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batchSize = 128\n",
    "numTraining = trainData_.shape[0]\n",
    "displayStep = 10\n",
    "\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# def accuracy(predictions, labels, labels_one_hot = None):\n",
    "#     # The input labels are a One-Hot Vector\n",
    "#     if labels_one_hot:\n",
    "# #         print (predictions)\n",
    "# #         print (predictions.shape[0])\n",
    "# #         print (np.argmax(labels, 1))\n",
    "# #         print (np.argmax(predictions, 1))\n",
    "#         return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "#     else:\n",
    "#         return (100.0 * np.sum(np.argmax(predictions, 1) == np.reshape(labels, [-1])) / predictions.shape[0])\n",
    "\n",
    "    \n",
    "def train_network():\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        epoch = 1\n",
    "        while epoch*batchSize < numTraining:\n",
    "            \n",
    "#             print ((epoch-1)*batchSize, epoch*batchSize)\n",
    "            batchData = trainData_[(epoch-1)*batchSize : epoch*batchSize]\n",
    "            batchLabels = trainLabels_[(epoch-1)*batchSize : epoch*batchSize]\n",
    "\n",
    "            sess.run(optimizer, feed_dict={trainData: batchData, trainLabels: batchLabels})\n",
    "\n",
    "            \n",
    "            if epoch % displayStep == 0:\n",
    "                loss, acc = sess.run([loss_CE, accuracy], feed_dict={trainData: batchData, trainLabels: batchLabels})\n",
    "                print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "                \n",
    "            epoch += 1\n",
    "#             break\n",
    "            \n",
    "\n",
    "\n",
    "# print (graphDict)\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.52622551],\n",
       "         [ 0.68646508],\n",
       "         [ 0.65008277]],\n",
       "\n",
       "        [[ 0.06481812],\n",
       "         [ 0.54809189],\n",
       "         [ 0.76726586]],\n",
       "\n",
       "        [[ 0.83489174],\n",
       "         [ 0.75896871],\n",
       "         [ 0.25165305]],\n",
       "\n",
       "        [[ 0.13270801],\n",
       "         [ 0.58833188],\n",
       "         [ 0.14629339]],\n",
       "\n",
       "        [[ 0.7359888 ],\n",
       "         [ 0.08913432],\n",
       "         [ 0.66141826]]],\n",
       "\n",
       "\n",
       "       [[[ 0.05585782],\n",
       "         [ 0.69977093],\n",
       "         [ 0.52322626]],\n",
       "\n",
       "        [[ 0.97286582],\n",
       "         [ 0.22512116],\n",
       "         [ 0.48032147]],\n",
       "\n",
       "        [[ 0.15738663],\n",
       "         [ 0.01338428],\n",
       "         [ 0.57128853]],\n",
       "\n",
       "        [[ 0.30658212],\n",
       "         [ 0.24820569],\n",
       "         [ 0.77591407]],\n",
       "\n",
       "        [[ 0.39811641],\n",
       "         [ 0.86327881],\n",
       "         [ 0.64881307]]],\n",
       "\n",
       "\n",
       "       [[[ 0.27618587],\n",
       "         [ 0.10348999],\n",
       "         [ 0.01123772]],\n",
       "\n",
       "        [[ 0.17071991],\n",
       "         [ 0.50098807],\n",
       "         [ 0.28569326]],\n",
       "\n",
       "        [[ 0.65558779],\n",
       "         [ 0.88648224],\n",
       "         [ 0.42478511]],\n",
       "\n",
       "        [[ 0.58333689],\n",
       "         [ 0.75098795],\n",
       "         [ 0.5400511 ]],\n",
       "\n",
       "        [[ 0.09007598],\n",
       "         [ 0.54880333],\n",
       "         [ 0.84454668]]]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_np = np.random.rand(5,3,3)\n",
    "array_np = array_np.reshape((-1, 5,3,1)).astype(np.float32)\n",
    "print(array_np.shape)\n",
    "array_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#             print ('')\n",
    "#             print ('training training training, training training training, training training training training training')\n",
    "#                 for no in np.arange(num_batches):\n",
    "#                     with open(self.train_batch_dir+'batch'+str(no)+'.pickle', 'rb') as f:\n",
    "#                         dataset = pickle.load(f)\n",
    "                        \n",
    "#                         batch_train_dataset = dataset['batch_train_dataset']\n",
    "#                         batch_train_labels = dataset['batch_train_labels']\n",
    "#                         batch_train_lenarr = dataset['batch_train_lenarr']\n",
    "                        \n",
    "#                         feed_dict= {graph_dict['x']: batch_train_dataset, \n",
    "#                                     graph_dict['y']: batch_train_labels,\n",
    "#                                     graph_dict['x_lenarr']: batch_train_lenarr}\n",
    "            \n",
    "#                         if new_state_ is not None:\n",
    "#                             feed_dict[graph_dict['init_state']] = new_state_\n",
    "\n",
    "#                         new_state_, loss_, opt, tp = sess.run([graph_dict['new_state'],\n",
    "#                                                             graph_dict['loss'],\n",
    "#                                                             graph_dict['optimizer'],\n",
    "#                                                             graph_dict['prediction']], \n",
    "#                                                             feed_dict=feed_dict)\n",
    "                        \n",
    "#                         training_loss += loss_\n",
    "#                         acc = self.accuracy(tp, batch_train_labels)\n",
    "                    \n",
    "                        \n",
    "#                         print ('accuracy of the training batch %d is: '%no, acc)\n",
    "                        \n",
    "                        \n",
    "#                         if (no%valid_after_batches==0 and no!=0):\n",
    "#                             print ('Average Loss till the training batch %d is: '%no, training_loss/no)\n",
    "#                             print ('')\n",
    "#                             print ('crossvalid crossvalid crossvalid, crossvalid crossvalid crossvalid, crossvalid crossvalid crossvalid')\n",
    "#                             self.cross_valid(sess,graph_dict)\n",
    "#                             print ('')\n",
    "#                             print ('training training training, training training training, training training training training training')\n",
    "                            \n",
    "#                 print ('All %d Batches Done.................................'%num_batches)\n",
    "#                 print ('')\n",
    "#                 print ('')\n",
    "                \n",
    "#                 if verbose:\n",
    "#                     print(\"Average training loss for Epoch\", epoch, \":\", training_loss/num_batches)\n",
    "            \n",
    "#             if isinstance(path_save_model, str):\n",
    "#                 graph_dict['saver'].save(sess, path_save_model)\n",
    "    \n",
    "\n",
    "# graph = tf.Graph()\n",
    "# with graph.as_default():\n",
    "#     # Define input data, valid data and test data\n",
    "#     tf_trainDataset = tf.placeholder(tf.float32, shape=(batchSize, image_size, image_size))\n",
    "#     tf_trainLabels = tf.placeholder(tf.float32, shape=(batchSize, numLabels, image_size))\n",
    "\n",
    "#     # Define weights first normal weights are taken.\n",
    "#     # The weights are shared accross all the neurons for one Kernel and we have one bais for each kernel.\n",
    "    \n",
    "#     convlayer1_bias = tf.Variable(tf.Zeros(kernelSize))\n",
    "#     convlayer2_bias = tf.Variable(tf.Zeros(kernelSize))\n",
    "# #     layer3_wghts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28 // 4 * 28 // 4 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convLayer(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxPoolLayer(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    # Convolution Layer\n",
    "    conv1 = convLayer(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxPoolLayer(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = convLayer(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxPoolLayer(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "#     fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, 10]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([10]))\n",
    "}\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.05).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1280, Minibatch Loss= 199.656830, Training Accuracy= 0.13281\n",
      "Iter 2560, Minibatch Loss= 14.407655, Training Accuracy= 0.09375\n",
      "Iter 3840, Minibatch Loss= 8.168202, Training Accuracy= 0.09375\n"
     ]
    }
   ],
   "source": [
    "numTraining = 200000\n",
    "training_iters = numTraining\n",
    "displayStep = 10\n",
    "display_step = 10\n",
    "batchSize = 128\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.initialize_all_variables())\n",
    "#     epoch = 1\n",
    "#     while epoch*batchSize < numTraining:\n",
    "\n",
    "# #             print ((epoch-1)*batchSize, epoch*batchSize)\n",
    "#         batchData = trainData_[(epoch-1)*batchSize : epoch*batchSize]\n",
    "#         batchLabels = trainLabels_[(epoch-1)*batchSize : epoch*batchSize]\n",
    "\n",
    "#         sess.run(optimizer, feed_dict={x: batchData, y: batchLabels})\n",
    "\n",
    "\n",
    "#         if epoch % displayStep == 0:\n",
    "#             loss, acc = sess.run([cost, accuracy], feed_dict={x: batchData, y: batchLabels})\n",
    "#             print (\"Iter \" + str(epoch*batchSize) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "            \n",
    "#         epoch += 1\n",
    "#         break\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batchSize < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batchSize)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            print (\"Iter \" + str(step*batchSize) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "# dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    \n",
    "# tf Graph input\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convLayer(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def poolLayer(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(weights, biases):\n",
    "    # Reshape input picture\n",
    "#     x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    x = tf.placeholder(tf.float32, [128, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.float32, [128, n_classes])\n",
    "\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = convLayer(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = poolLayer(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = convLayer(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = poolLayer(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "#     fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    \n",
    "#     Construct model\n",
    "# pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "    \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "x = tf.placeholder(tf.float32, [128, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [128, n_classes])\n",
    "\n",
    "\n",
    "pred = conv_net(weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_36' with dtype float and shape [128,28,28,1]\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=[128,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'Placeholder_36', defined at:\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-66-77e81ff6dd4f>\", line 23, in <module>\n    pred = conv_net(weights, biases)\n  File \"<ipython-input-65-6f0a41caf4bf>\", line 18, in conv_net\n    x = tf.placeholder(tf.float32, [128, 28, 28, 1])\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1212, in placeholder\n    name=name)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1530, in _placeholder\n    name=name)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    451\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_36' with dtype float and shape [128,28,28,1]\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=[128,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-4dc2745fd499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainLabels_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_36' with dtype float and shape [128,28,28,1]\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=[128,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'Placeholder_36', defined at:\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-66-77e81ff6dd4f>\", line 23, in <module>\n    pred = conv_net(weights, biases)\n  File \"<ipython-input-65-6f0a41caf4bf>\", line 18, in conv_net\n    x = tf.placeholder(tf.float32, [128, 28, 28, 1])\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1212, in placeholder\n    name=name)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1530, in _placeholder\n    name=name)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "batchSize = 128\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "#         batchData, batchLabels = mnist.train.next_batch(batch_size)\n",
    "        batchData = trainData_[(step-1)*batchSize : step*batchSize]\n",
    "        batchLabels = trainLabels_[(step-1)*batchSize : step*batchSize]\n",
    "        # Run optimization op (backprop)\n",
    "        opt = sess.run(optimizer, feed_dict={x: batchData, y: batchLabels})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batchData,\n",
    "                                                              y: batchLabels})\n",
    "            print (\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "#     Calculate accuracy for 256 mnist test images\n",
    "#     print (\"Testing Accuracy:\", \\\n",
    "#         sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "#                                       y: mnist.test.labels[:256],\n",
    "#                                       keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
