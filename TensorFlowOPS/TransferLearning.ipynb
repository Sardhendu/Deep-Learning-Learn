{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNote : Before running the code below ensure you have all the data in TFRecord and appertaining format.\\n        Else : Follow the code inside TensorFlowIO module to create such files. THis module assumes that \\n        the data are in their proper directories\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.models import slim\n",
    "from tensorflow.models.slim.preprocessing import inception_preprocessing\n",
    "\n",
    "from tensorflow.contrib.slim.python.slim.data import tfexample_decoder, dataset\n",
    "import os, time\n",
    "\n",
    "\"\"\"\n",
    "Note : Before running the code below ensure you have all the data in TFRecord and appertaining format.\n",
    "        Else : Follow the code inside TensorFlowIO module to create such files. THis module assumes that \n",
    "        the data are in their proper directories\n",
    "\"\"\"\n",
    "# Code Source : https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory Listings\n",
    "\n",
    "# Log file creation\n",
    "logDir = './log'\n",
    "\n",
    "# State the image size we are resizing\n",
    "imageSize = 299 # the default size for inception\n",
    "\n",
    "# State the path where the label file is stored\n",
    "labelFile = \"/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/TensorFlowOPS/flowers/labels.txt\"\n",
    "labels = open(labelFile, 'r')\n",
    "\n",
    "# Dictionary to refer each label to its string name\n",
    "labelsToNameDict = {}\n",
    "for record in labels:\n",
    "    label, stringName = record.split(':')\n",
    "    stringName = stringName[:-1]\n",
    "    labelsToNameDict[int(label)] = stringName\n",
    "    \n",
    "# Record the file pattern for the TFRecord files\n",
    "filePattern = \"flowers_%s_*.tfRecord\"\n",
    "\n",
    "# A dictionary describing the dataset, to be required by tensorflow dataset Class\n",
    "itemToDescription = {\n",
    "    'image': \"A 3-channel RGB coloured five different types of flowers, tulips, sunflower, roses, dandelion, daisy\",\n",
    "    'label': \"A label value defined to each flower 1: dandelion, 2:roses, 3:sunflower, 4:tulips\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function details:\n",
    "\n",
    "1. get_splits: It allows us to obtain a specific split form the disk. We store two different types of files in the disk \"trai file and validation file\". These files were split into two and get_split helps us to ge the required split.\n",
    "\n",
    "In the process we also collect some information such as number_of samples in the split, and etc.\n",
    "\n",
    "* Two very important functions are keysTOFeature and itemsToHandlers/\n",
    "* **keysToFeature**: \n",
    "\n",
    "2. DatasetDataProvider: The motive we have here is that we need tensors from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/TensorFlowOPS/flowers/flowers_train_*.tfRecord\n",
      "[]\n",
      "Total records to to be trained are:  0\n",
      "{'image/encoded': FixedLenFeature(shape=(), dtype=tf.string, default_value=''), 'image/format': FixedLenFeature(shape=(), dtype=tf.string, default_value='jpg'), 'image/class/label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=<tf.Tensor 'zeros_12:0' shape=() dtype=int64>)}\n",
      "<tensorflow.contrib.slim.python.slim.data.tfexample_decoder.TFExampleDecoder object at 0x11bb31320>\n"
     ]
    }
   ],
   "source": [
    "def getSplits(splitName, datasetDir, filePattern):\n",
    "    if splitName not in ['train','validation']:\n",
    "        raise ValueError('The spllit name %s is not recognized, Make sure they are either train, validation or test'%splitName)\n",
    "\n",
    "    # create a path for data IO: The pattern should be the split name\n",
    "    filePatternPath = os.path.join(datasetDir, filePattern%(splitName))\n",
    "    print (filePatternPath)\n",
    "\n",
    "    # Count the total number of training samples:\n",
    "    filePattern = filePattern+\"%s\"%(splitName)\n",
    "    tfRecordsFilesPath = [os.path.join(datasetDir, file) for file in os.listdir(datasetDir) if file.startswith(filePattern)]\n",
    "    print (tfRecordsFilesPath)\n",
    "\n",
    "    # We now count all the records inside the tfRecord files that are separated into multiple shards\n",
    "    numSamples = 0\n",
    "    for tfRecord in tfRecordsFilesPath:\n",
    "        for record in tf.python_io.tf_record_iterator(tfRecord):\n",
    "            numSamples += 1\n",
    "\n",
    "    print ('Total records to to be trained are: ', numSamples)\n",
    "\n",
    "    # Define what type of reader\n",
    "    reader = tf.TFRecordReader\n",
    "    \n",
    "    # Create a keys to feature dictionary\n",
    "    keysToFeature = {\n",
    "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\n",
    "        'image/class/label': tf.FixedLenFeature(\n",
    "        [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "    print (keysToFeature)\n",
    "\n",
    "    # Create the dictionary for the decoder\n",
    "    itemsToHandlers = {\n",
    "        'image': tfexample_decoder.Image(),   \n",
    "        'label': tfexample_decoder.Tensor('image/class/label')\n",
    "    }\n",
    "    # tfexample_decoder is the module and Image in the class so basically the key imaage int the dictionary contains the \n",
    "    # object of class image as the value.\n",
    "    # Similarly the key Label also holds the obect of class Tensor in the value\n",
    "\n",
    "    decoder = tfexample_decoder.TFExampleDecoder(keysToFeature, itemsToHandlers)\n",
    "    print (decoder)\n",
    "\n",
    "    labelsTONameDict = labelsToNameDict\n",
    "\n",
    "    dataetObj = dataset.Dataset(\n",
    "            data_sources = filePatternPath,\n",
    "            decoder = decoder,\n",
    "            reader = reader,\n",
    "            num_readers = 4,\n",
    "            num_samples = numSamples,\n",
    "            num_classes = 5,\n",
    "            labels_to_name = labelsTONameDict,\n",
    "            items_to_descriptions = itemToDescription)\n",
    "    \n",
    "    return dataetObj\n",
    "\n",
    "datasetDir = \"/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/TensorFlowOPS/flowers\"\n",
    "split_name = \"train\"\n",
    "# filePattern = \"flowers_\"\n",
    "filePattern = \"flowers_%s_*.tfRecord\"\n",
    "\n",
    "dataset = getSplits(splitName=split_name, datasetDir=datasetDir, filePattern=filePattern)\n",
    "# 'image': slim.tfexample_decoder.Image(),\n",
    "#     'label': slim.tfexample_decocer.tensor('image/class/label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
